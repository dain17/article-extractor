What if an armed, artificial-intelligence-enabled attack drone detects an enemy fighter jet, uses long-range sensors to confirm the target before attacking with a precision-guided air-to-air missile?

What if an unmanned fighter or advanced drone, operated with various levels of advanced AI-informed algorithms, engaged in fast air-to-air combat maneuvers in a direct dogfight or close-in engagement with a manned enemy fighter?

These questions, which raise substantial tactical, strategic and command and control questions, are fast becoming a near-term reality.

“Autonomous systems going up against a manned system in some kind of air-to-air engagement ... is a bold idea,”  Lt. Gen. “Jack” Shanahan, Director, Joint Artificial Intelligence Center, told The Mitchell Institute for Aerospace Studies in a special video interview series.

Shanahan explained that, while autonomy now exists in various forms of great operational significance, AI-enabled autonomy brings a new frontier of warfare possibilities now being explored by the Pentagon in greater depth.

“AI-enabled autonomy is where we will see some big capabilities come together,” he said.

Autonomy driven by AI does bring a range of new technical, tactical and strategic implications, such as bringing new paradigms of decision-making, problem solving and operations.

Essentially, platforms driven by advanced AI will be capable of discerning, processing and analyzing vast amounts of information in near real-time, something which not only speeds up “sensor-to-shooter” time but also enables a much greater range of operational activity without a need for human intervention.

Instead of merely following pre-determined navigational “waypoints” established through GPS, something which has been underway for quite some time, drones and even fighter-jets will be able to receive new input, perform in-flight analytics and then make impactful decisions autonomously.

While humans will retain the requisite measures of command and control, AI can facilitate the ability for an unmanned system to, for instance, quickly adjust flight in response to new sensor information. This could include the processing of force location or navigational data independently or even networking intelligence data between nearby manned platforms, unmanned platforms and human-operated ground command centers.

For instance, a drone or unmanned fighter could be operating in a high-risk area when it comes upon enemy troop formations or terrain configurations of great tactical significance, bounce that new information against a vast and seemingly limitless database of information to perform analytics and make necessary adjustments.

Perhaps the on-board computer can access an intelligence database indicating previously successful courses of action in these circumstances, analyze information about enemy capabilities, assets and weapons, and inform the unmanned platform regarding the best immediate course of action? An on-board computer could instantly weigh a host of variables to independently make calculations previously determined by humans.

It certainly could be said that the F-35’s well-known “sensor fusion,” which organizes otherwise disparate sensor information onto a single screen for the pilot, is an early application of AI.

Emerging or future AI-enabled autonomy will incorporate a vastly superior wealth or range of information, improve processing and analytics, and perform decision-making related to a host of complex dynamics without needing humans.

Procedural and analytical functions such as information management and data processing can all be done much more efficiently than humans, all while leaving human cognition in an ultimate controlling role.

The speed of calculations and the increasing pace at which AI-informed systems can acquire, process and analyze new information in real-time are in fact expected to enable unmanned dogfighting, combat maneuvering and tactical decision-making.

“We will see small numbers of humans controlling larger numbers of machines. In some cases, it will be machine-to-machine with humans in the loop,” Shanahan said.

Of course, at least at the moment, all of this rests upon a fundamental and, as of yet, unchanging premise, namely that ultimate control must remain with humans able to utilize those characteristics unique to human cognition.

“The only failure we will have is a failure of imagination,” Shanahan added.

-- Kris Osborn is the Managing Editor of Warrior Maven and The Defense Editor of The National Interest --